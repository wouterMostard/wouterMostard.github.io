---
title: 'Contrastive loss for multimodal data'
date: 2021-07-04
---

Introduction
======
One important aspect of learning a good multimodal representation is that the multimodal pair consists of a visual representation $x_i$ and a textual representation $y_i$ are close together into a shared space. One method that does just this has been proposed in this paper(https://arxiv.org/pdf/2010.00747.pdf). In this short blog post we will describe this method.

Multimodal Contrasstive loss
=======
The overall idea is the following. Let's say you pick a batch of $N$ image text pairs denoted by a matrix $X$ and $Y$ respectively. If you assume that all the other pairs in the set are independen from a given pair ($x_i$, $y_i$) then the goal of your model would be to increase the similarity of this pair while also "pushing" away the images or texts that do not belong to this pair. Let's say we focus on the images and we are interested into learning a margin between the correct text pair and the other ones that are wrong. 

One simple method is using the softmax function where the optimal value is achieved when only $x_i$ has a non-zero value. 

$$
softmax(x) = \frac{e^{x_i}}{\sum_t e^{x_t}}
$$

So how could you apply this in our case? The logical method would be to increase the similarity between the valid pair while pushing all the other ones to zero, i.e. making these vector orthogonal to each other. If you assume that the vectors are L2 normalised you can easily determine how "similar" two vectors are by taking the dot product of these two vectors.  For our case this means that we take the dot product of a given image representation with all the given text representations

$$
pairloss(X, Y) = \frac{e^{x_i^T y_i}}{\sum_j e^{x_i^Ty_i}}
$$

Notice that this loss is minimized when the similarity between the valid pair is 1 and with all the other text pairs is 0, i.e. $\frac{1}{1} = 1$. By taking the log of this loss you achieve the actual loss, which is 0 ($log(1) = 0$). This loss is calculated for each other pair in the training batch. See the image below for a graphical depiction. 

Since we calculate the loss for each input pair we take the mean loss in order to get a constant loss. Furthermore, since the log of a softmax output is always negative we have to take the negative of the output in order to get to our final loss function 

$$
image2textloss(X, Y) = -\frac{1}{N}\sum_i^Nlog(\frac{e^{x_i^T y_i}}{\sum_j e^{x_i^Ty_i}})
$$

So in conclusion, this loss function is minimized if all the pairs in the training batch are orthogonal to all other instances in the batch. In the future we will be trying to incorporate this loss function into a mulitmodal learning algorithm as has been applied in (https://arxiv.org/pdf/2102.05918.pdf)



