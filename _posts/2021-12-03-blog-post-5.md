---
title: 'Open set recognition'
date: 2021-07-04
---

Introduction
======
One significant drawback of traiditional approaches in classification is that it is assumed that all the target classes that are presented in the training set represent all the classes that an algorithm can find the test set. In production environment this is not the case, especially in large-scale domains such as on the web.

In this blog post I will shortly describe what the problem is and how these can be overcome. As an example lets say that we have a simple binary classification problem where the two classes are normally distributed with a mean at 5 and a mean at 10. 

<img src="http://woutermostard.github.io/files/train_data.jpg" align="middle" width="500" height="300">

Why the classes are normallhy distributed will be discussed later. For now we are primarely interested in finding the most probable class give a input $x$, i.e. $P(y|x)$. A simple solution would be to train a logistisc regression classifier and plot the probablity for class 1. 

<img src="http://woutermostard.github.io/files/prob.jpg" align="middle" width="500" height="300">

As you can see the model will classify any example that has as input approximately $x > 6$ will be classified as belonging to $C_1$. In a scenario where we know that there are only 2 classes this would be fine. However, in most practical applications we do not know all the target classes. For example, it could very well be that when $x > 14$ there is a new class that we haven't seen during testing.

<img src="http://woutermostard.github.io/files/new_point.jpg" align="middle" width="500" height="300">

In our simple logistic regression classifier this will be classified as belonging to class 1, while the sample does seem quite different. In order to overcome this we would like to model the probability of an example a priori belonging to a class and not relative to the other classes, i.e. $P(c \in C  | x)$. How to model this distribution is very much an open problem. For now I assumed that the classes are normally distributed such that we can just fit a distribution over all the classes. 

<img src="http://woutermostard.github.io/files/pdf.jpg" align="middle" width="500" height="300">

Now in order to have an actual prediction for the picked class we do 2 things: 1) We select the most probable class from the classifier and 2) we calculate the probability of the test datapoint being sampled from the distribution of the most probable target class. If we combine these two steps we get a probability threshold that is more suitable for open set recognition

<img src="http://woutermostard.github.io/files/score.jpg" align="middle" width="500" height="300">

Please note that the original PDFs and our scores are quite a like. This is because the optimal decision boundary given 2 gaussians will look much a like the logitistic regression classification. Do note that in the score function the probability of belonging to class 2 stays flat until $x=6$ and als nicely flattens out until a score of $x \approx 16$. Now our previously given test datapoint at $x=17.5$ will nicely have a score of around 0. 

Hopefully this introduction into open-set recognition gave some insights. Ofcourse this is a simplified toy problem, in real-world problems it is qutie unlikely that you will be able to fit simple distributions over the target classes and quickly you run into issues like the curse of dimensionality. In future work I would like to investigate other measures to determine $P(C \in C | x)$. For example by modelling the distribution of the distance from datapoints from the support vectors in a support vector machine. 