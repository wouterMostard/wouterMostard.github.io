---
title: 'WIP: Introduction into JAX and Haiku'
date: 2021-04-07
---

Introduction
======

JAX is a simple python libary that allows for automatic differentation and optimization of linear algebra optimization. 
Why differentation is required is obvious, as it is needed for passing information back through the network. Using 
XLA (Accelerated Linear Algebra) is maybe a bit less obvious. The important thing to note is that for example neural 
 networks are simply a sequential application of matrix multiplications. XLA allows for optimization of 
these linear algebra operations by compiling the model and combining various steps into a single kernel.

In this short blog bost I will show how you can develop a simple logistisc regression model on a random classification 
dataset using JAX. Furthermore, we will show how Haiku (which is a simple wrapper arround JAX) can be used to develop more 
complicated models. In our  case we will develop a CNN for performing MNIST digit classifciation  
 

Automatic differentiation of simple functions 
======
So the most important step of training in neural networks is the ability to propagate an error signal back through a 
given network. The architecture of this network can be anything, as long as it is differentiable. Calculating the derivatives
can of course be quite cumbersome but luckily JAX has functionality called `grad()` that does this all for you. Below
there is a code snippet that shows how we calculate the first and the second (or Hessian) of the sigmoid function 

```
from jax import grad, jit # Load the automatic differentation and just in time compilation
import jax.numpy as jnp # duck typing numpy 
import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
    return 1 / (1 + jnp.exp(-x))

gradient = grad(sigmoid) # calculates the gradient w.r.t. x
hessian = grad(gradient)

x_range = jnp.linspace(-5, 5, 100)
plt.plot(x_range, [gradient(x) for x in x_range], label='derivative')
plt.plot(x_range, [hessian(x) for x in x_range], label='hessian')
plt.plot(x_range, sigmoid(x_range), label='$\sigma$')
```

The plot belows nicely shows that `grad()` indeed nicely calculated the derivatives of the function and you can see 
a saddle point, i.e. where the second derivative is 0, at 0. As expected. 

<img src="http://woutermostard.github.io/files/differ.png" align="middle" width="500" height="300">

Create simple Logistic regression classifier using JAX 
======

So no to go into a first example of using this functionality in classification. First we create some binary data set for 
classification of 500 samples, split the data into train and test and standardize the data accordingly. 
Standardizing is required because it could be the case that each feature is on a different scale and thus
have a different influence on the gradient. When the data is standardized each feature will have equal importance on 
the direction of the gradient. 

```
import jax.numpy as jnp
from jax import grad
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.datasets import make_classification
from jax import random
from sklearn.metrics import accuracy_score

X, y = make_classification(n_classes=2, n_samples=500)

X_train, X_test, y_train, y_test = train_test_split(X, y)
scaler = StandardScaler()
scaler.fit(X_train)
X_train_s = scaler.transform(X_train)
X_test_s = scaler.transform(X_test)

c_0 = 1.0
w_0 = random.normal(random.PRNGKey(0), (X.shape[1], ))
```

the `c` and `w` are the learnable parameters. `c` is the bias which we have set to `1`. `w` is the weight vector which 
wer initialise using a random number generator. Note the `random.PRNGKey(0)`, this sets the random number generator with seed `0`.
In order to perform gradient descent we need to specify how we go from input to output (our prediction) and how our loss 
function is determined.

```
def predict(c, w, input_):
    return sigmoid(jnp.dot(input_, w) + c)

@jit
def cost(c, w, X, y, eps=1e-14, lmbd=0.1):
    p = predict(c, w, X)
    
    return -jnp.mean(y * jnp.log(p) + (1 - y) * jnp.log(1 - p))
```  

Note that the prediction is just a linear transformation given the feature weights and a bias which is subsequently squeezed
between `0` and `1` using the `sigmoid` function. Furthermore, note that we use the `@jit` decorator above the cost function method.
This decorator allows for JAX to pre-compile some of the steps that we perform in this function, making it significantly it faster.
So where does that loss function come from? If you assume that the input `X` has been the input that generated the corresponding
output labels and that the data is i.i.d. you would like to maximize a model that gives these predictions given the output. 
Specifically, the cost function is based on the negative log likelihood of the Bernoulli distribution. The Bernoulli distribution is given by

$$
p^y * (1 - p)^{1 - y}
$$

The likelihood of this distribution is given by the product of all the examples given the assumption that they are i.i.d

$$
\prod_n p^y_n * (1 - p)^{1 - y_n}
$$

For numerical convenience we take the log of this likelihood and the negative value

$$
- \frac{1}{n} \sum_n y_n * log(p) + log(1 - p) * (1 - y_n)
$$

Which is equal to the equation given in the cost function. Given this formulation we want to optimise for `c` and `w` using gradient descent

``` 
n_iter = 500
w = w_0
c = c_0
accuracies_train = []
accuracies_test = []

for i in range(n_iter):
    c_current = c
    c -= eta * grad(cost, argnums=0)(c_current, w, X_train_s, y_train)
    w -= eta * grad(cost, argnums=1)(c_current, w, X_train_s, y_train)
    
    predictions_train = (predict(c, w, X_train_s) > 0.50).astype(int)
    predictions_test = (predict(c, w, X_test_s) > 0.50).astype(int)
    
    accuracies_train.append(accuracy_score(y_pred=predictions_train, y_true=y_train))
    accuracies_test.append(accuracy_score(y_pred=predictions_test, y_true=y_test))
```
    
The most important happens at `c` and `w` in the for loop. Here you can see that we iteratively update the values of `c` 
and `w` by picking the first or the second argument of the gradient respectively (`argnums=x`) Classifications are obtained
by thresholding the probabilities at `0.50`. Given the following graph you can see that our model learned the classification
mapping going from a 20 dimensional input vector to the posterior probability of a data point belonging to class 1 $P(c=1 | x)$

<img src="http://woutermostard.github.io/files/accs.png" align="middle" width="500" height="300">

Which is further shown by plotting the prediction scores

```
predictions = (predict(c, w, X_test_s) > 0.50).astype(int)

print(classification_report(y_pred=predictions, y_true=y_test))     

              precision    recall  f1-score   support

           0       0.90      0.92      0.91        59
           1       0.92      0.91      0.92        66

    accuracy                           0.91       125
   macro avg       0.91      0.91      0.91       125
weighted avg       0.91      0.91      0.91       125

```

MNIST classification using MNIST
======

TODO
