---
title: 'DRAFT: Unsupervised representation learning using graph neural networks Part 1'
date: 2021-05-23
---

Introduction
======
Unsupervised learning is een van de hoekstenen van kunstmatige intelligentie. Unsupervised learning lit ook veel dichter
bij hoe wij als mensen leren dan supervised learning. Natuurlijk krijgen wij bij onze opvoeding wel een beetje mee hoe de 
wereld er uit ziet onder supervisie van onze ouders. Je ouders hebben je bijvoorbeeld laten zien hoe bepaald fruit er uit 
ziet, maar zeker niet alles. Al het volgende heb je zelf geleerd door het maken van connecties tussen de verschillende 
soorten fruit. In deze x delige series over unsupervised learning gaan we hier op in en gaan we kijken hoe methodes binnen 
ene enthousiast gebied genaamd graph neural networks gebruikt kunnen worden voor het semi-supervised leren van representaties.

Deze blog begint met een korte introductie in graphs, een stukje geschiedenis en hoe ze tegenwoordig worden toegepast. 
Vervolgens kijken we naar modellen die het mogelijk hebben gemaakt om deze methodes te gebruiken op een grote schaal door 
midden van convoluties.  


Graphs 
======

Een graph is een datastructuur waarbij de relaties tussen verschillende notes worden aangegeven. Eeen simpel voorbeeld 
van een graph is bijvoorbeeld een wegennet. Hier zijn de verschillende steden de nodes en de wegen tussen de steden de edges
Formeel bestaat een graph G dus uit een set met Vertices (de nodes), en Edges (de wegen) G(V, E).

Hoe is dit toepasbaar binnen machine learning? In normale classificatie problemen heb je alleen de individuele datapunten 
beschikbaar. Bijvoorbeeld in het maken van een computer vision classificatie systeem heb je N afbeeldingen waarop je het 
systeem traint. Maar wat het systeem niet weet is hoe de afbeeldingen in relatie tot elkaar staan. Een interessant voorbeeld
waar het weten van relationele data is te vinden in [x]. Hier zijn de nodes een x aantal woorden die semantsiche waarden hebben
en de edges zijn de frequentie waarin de woorden samen worden gebruikt. De auteurs tonen aan dat de relatie tussen de frequentie
van het samen gebruiekn van woorden voor author verificiation. 

Information flow through graphs 
======

Dus hoe leer je op graphs? Een belangrijk onderdeel hiervoor is hoe je informatie door de graph laat vloeien. Zoals beschreven
in de introductie heeft elke node een aantal nodes waarvan hij informatie ontvangt. Wat je kunt doen is die informatie samenvatten
en vervolgens zelf weer informatie doorgeven aan de neighboring nodes van de huidige node. 

Hoe combineer je informatie vanuit inkomende nodes? 1 belangrijk ding om te wetne is dat voor elke node een verschillende
aantal incoming nodes kunnen zijn en die variance dus mogelijk moet zijn. Om deze reden is het vrij gebruikelijk om operators
te gebruiken zoals het gemiddelde of de sum van de input. 


Practisch voorbeeld, multi-modal retrieval 
======

Aashish Misraa heeft recentelijk een draft paper uitgebracht waar ze de message passing van nabije nodes gebruiken voor het 
multi-modaal zoeken door afbeeldingen en hun bijbehorende anchorteksten. De graph structuur die ze hier aanbevelen is dat je
met een pre-traind neuraal netwerk de visuele NNs ophaalt van een afbeelding. Ook de anchor teksten die bij een afbeelding
horen worden geconnect met een link. 

Een nadeel van een graph is dat je vaak de hele graph moet kennen om er inference op te doen. GraphSage heeft een manier 
bedacht hoe je nieuwe nodes kan toevoegen tijdens inference en hoe je veel grotere node graphs kan gebruiken. Het belangrijkste 
om te weten is dat eigenlijk de representatie van een node alleen afhangt van alle nodes die x van de target node afzitten.
Het kan soms zijn dat het alsnog een vrij veel nodes zijn, op die manier kan je dan zorgen voor een max aantal negatieve nodes. 
In dit project gebruiken we PyTorch Geometric, een vrij nieuwe libary die gebruikt kan worden voor het het leren op graphs.
De train loader zal er zo uitzien

```
class NeighborSampler(RawNeighborSampler):
    def sample(self, batch):
        batch = torch.tensor(batch)
        row, col, _ = self.adj_t.coo()

        pos_batch = random_walk(row, col, batch, walk_length=1, # so a direct neighbor is the pos example (to be contracted)
                                coalesced=False)[:, 1]

        neg_batch = torch.randint(0, self.adj_t.size(1), (batch.numel(), ), # Random nod in the adj matrix is to be distanced
                                  dtype=torch.long)

        batch = torch.cat([batch, pos_batch, neg_batch], dim=0)
        return super(NeighborSampler, self).sample(batch)

train_loader = NeighborSampler(data.edge_index, sizes=[25, 10], batch_size=512, 
                               shuffle=True, num_nodes=data.num_nodes)
```

wat pos_batch een aantal positieve nodes van een gegeven node zijn. De parameter `walk_length=1` betekent dat alleen de 
directe neighbors gesampled worden als positieve nodes. Voor de negatieve samples worden willekeurige nodes gebruikt.
`batch.numel()` betekent dat er zoveel negatieve worden gesamples als dat er in de batch zijn. Die positieve en negatieve
examples worden vervolgens aan elkaar geknoopt. Omdat dit alsnog veel nodes kunnen zijn wordt de `sample()` method aangeroepen
om er een x aantal uit te halen. 

Bij het aanmaken kan je zien dat we de `data.edge_index` meegeven. Dit zijn alle edges in de graph. de parameter sizes
betekent dat we uit de 1 NN 25 examples samplen en uit 2NN 10 sampelen. De totale batch size is 512.  


Eenmaal met de sampling in dienst moet er getraind worden. Wat je vervolgens doet is dat je op een unsupervised manier 
door de data heen gaat.Dit wil zeggen dat je door middel van 2 loss functies nodes die aan elkaar vast zitten naar elkaar 
toe gaat trekken en nodes die uit elkaar stana uit elkaar haalt. Volgens de graph sage paper kan je dat met de volgende \
vergelijkingen doen

$
    J_g(z_u) = -log(\sigma(Z_u^Tz_v)) - Q * E_{v_n \approx P_n(v)} log(\sigma(-z_u^Tz_{v_n}))
$

Where $z_u$ is the target node and $z_v$ occurs near. $Q$ is the sample size and $E_{v_n \approx P_n(v)}$ states the distribution
of negative examples that is being sampled from. Note that the output of the GraphSage nodes is always normalized so the
dot product is the same is calculating the cosine similarity.  

Die je in PyTorch zo kunt implementeren

```
        pos_loss = F.logsigmoid((out * pos_out).sum(-1)).mean()
        neg_loss = F.logsigmoid(-(out * neg_out).sum(-1)).mean()
        loss = -pos_loss - neg_loss
```


Citations 
======

